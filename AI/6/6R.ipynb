{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-P4IWwSX7RF8"
      },
      "source": [
        "# Домашнее задание по теме «Нейронные сети»\n",
        "\n",
        "Сегодня ты продолжишь решать задачу классификации чисел MNIST с помощью нейросети.\n",
        "\n",
        "В этом домашнем задании тебе нужно:\n",
        "- добавить вычисление метрики на этапе валидации;\n",
        "- вспомнить про нормализацию данных и применить её;\n",
        "- познакомиться с популярным блоком нейросети `BatchNorm`;\n",
        "- применить шедулер."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cKqGHU285u8"
      },
      "source": [
        "## Задача 1. Метрика на валидации [3 балла]\n",
        "\n",
        "На семинаре во время валидации нейросети мы считали `loss`. Это вполне корректное действие, и так можно и нужно валидироваться. Однако `loss` далеко не всегда понятен для бизнеса как мера качества решения задачи. Для этого существуют метрики.\n",
        "\n",
        "Проблема в том, что не все метрики можно оптимизировать напрямую. Но если нужно получить оценку качества работы нашего алгоритма именно на метрике, то вычислить её можно на этапе валидации.\n",
        "\n",
        "В этом и состоит первая задача. Для этого нужно:\n",
        "1. Добавить вычисление метрики `Accuracy` из `sklearn` после этапа валидации на эпохе (подробности в коде). **[1 балл]**\n",
        "2. Добавить в `print` лог, который выводит значение `Accuracy` на валидации. **[0,5 балла]**\n",
        "3. Обучить модель с семинара с реализованным вычислением `Accuracy` **[0,5 балла по метрике]**. Не забудь скачать веса лучшей модели и прикрепить их к домашнему заданию.\n",
        "4. Описать, что получилось. Обрати особое внимание, как соотносится `loss` и значение метрики на валидации. Всегда ли оптимальная модель по `loss` оптимальна и по метрике? **[1 балл]**\n",
        "\n",
        "> **Важно.** Запомни, какой результат получился на валидации. Дальше ты будешь усложнять решение задачи. Это повлияет на качество её решения."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LW675Ie7_lHp"
      },
      "source": [
        "### Твоё решение задачи 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlM1YcEbCzK9"
      },
      "source": [
        "> **Подсказка.** Следующие несколько ячеек — код с семинара. Просто запусти их. Когда тебе потребуется что-то написать, это будет выделено жирным."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qFdXd77zC-v-"
      },
      "outputs": [],
      "source": [
        "# Импортируем нужные пакеты\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.datasets import MNIST\n",
        "\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vuT-0hS1C-v_"
      },
      "outputs": [],
      "source": [
        "# Загружаем датасет\n",
        "train_ = MNIST('../Datasets', # Папка для сохранения или загрузки\n",
        "              download=True, # Если нет в папке, скачиваем из интернета\n",
        "              train=True,\n",
        "              ) # train-подвыборка\n",
        "test = MNIST(\"../Datasets\", download=True, train=False)\n",
        "\n",
        "# Для начала достанем все данные из нашего датасета\n",
        "X_train, y_train = train_.data, train_.targets\n",
        "X_test, y_test = test.data, test.targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "52c6-_jIC-wA"
      },
      "outputs": [],
      "source": [
        "# Определим класс датасета\n",
        "class DatasetMNIST(Dataset):\n",
        "\n",
        "  def __init__(self, X, y):\n",
        "    self.X = X.flatten(start_dim=1) / 255\n",
        "    self.y = y\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.y)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.X[idx], self.y[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rTMVcRaCC-wB"
      },
      "outputs": [],
      "source": [
        "# Определим новые датасеты\n",
        "train_ds = DatasetMNIST(X_train, y_train)\n",
        "test_ds = DatasetMNIST(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "SQn4W296C-wB"
      },
      "outputs": [],
      "source": [
        "# Определим DataLoader\n",
        "train_dl = DataLoader(\n",
        "    train_ds, # Наш датасет\n",
        "    batch_size=64, # Размер батча. Меньше 32, согласно многим исследованиям, ставить не рекоммендуется из-за потерь в качестве\n",
        "    shuffle=True, # Указываем, перемешивать ли данные перед каждой эпохой (проходом по данным). Для train-подвыборки всегда ставим True, кроме единичных исключений\n",
        "    drop_last=True, # Если наш последний батч будет неполным, то не обучаемся на нём\n",
        "    num_workers=4, # Указываем, сколько процессов будут собирать данные в батч. Обычно выбирают по числу ядер\n",
        "    persistent_workers=True # Используем, чтобы не создавать каждый раз новый процесс при обращении к DataLoader. Полезно для небольшого ускорения исполнения\n",
        ")\n",
        "\n",
        "test_dl = DataLoader(\n",
        "    test_ds, # Тестовый датасет\n",
        "    batch_size=64*4, # Для скорости можно установить значение больше, чем на train. Если только получаем предсказания, а не обучаемся, то нужно меньше ресурсов, а значит, в GPU поместится батч большего размера\n",
        "    shuffle=False, # Не будем перемешивать\n",
        "    drop_last=False, # И исключать неполный батч тоже не будем, потому что нам нужны предсказания для него\n",
        "    num_workers=4,\n",
        "    persistent_workers=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GslDuA7Acln5"
      },
      "outputs": [],
      "source": [
        "# Функция для одного шага обучения. Вставь код с семинара\n",
        "def train_step(batch, model, loss, optimizer, device):\n",
        "\n",
        "    # Обнуляем градиенты\n",
        "    model.zero_grad()\n",
        "\n",
        "    X, y = batch\n",
        "    # Раздели батч на данные и метку = batch\n",
        "    X = X.to(device)\n",
        "    y = y.to(device)\n",
        "\n",
        "    # Пропускаем данные через модель\n",
        "    # Логиты — выход из последнего слоя нейросети, но основе которых решается задача\n",
        "    logits = model(X)\n",
        "    # Считаем loss\n",
        "    l = loss(logits, y)\n",
        "\n",
        "    # Обратное распространение ошибки\n",
        "    l.backward()\n",
        "\n",
        "    # Шаг оптимизатора\n",
        "    optimizer.step()\n",
        "\n",
        "    return l.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "D0iuSPQ6DSeY"
      },
      "outputs": [],
      "source": [
        "# Функция для одного шага обучения\n",
        "def train_step(batch, model, loss, optimizer, device):\n",
        "\n",
        "    X, y = batch\n",
        "    X = X.to(device)\n",
        "    y = y.to(device)\n",
        "\n",
        "    model.zero_grad()\n",
        "\n",
        "    logits = model(X)\n",
        "    l = loss(logits, y)\n",
        "\n",
        "    l.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return l.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "MlTutuMNDS7v"
      },
      "outputs": [],
      "source": [
        "# Функция для обучения на эпохе\n",
        "def train(model, loss, optimizer, device, train_dataloader):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "\n",
        "    for batch in tqdm(train_dataloader):\n",
        "      loss_step = train_step(batch, model, loss, optimizer, device)\n",
        "      train_loss += loss_step / len(train_dataloader)\n",
        "\n",
        "    return train_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "vLqlFiqmDXNR"
      },
      "outputs": [],
      "source": [
        "# Функция для одного шага валидации\n",
        "def valid_step(batch, model, loss, device):\n",
        "\n",
        "      X, y = batch\n",
        "      X = X.to(device)\n",
        "      y = y.to(device)\n",
        "\n",
        "      with torch.no_grad():\n",
        "        logits = model(X)\n",
        "        l = loss(logits, y)\n",
        "\n",
        "      return logits.argmax(dim=-1).detach().cpu().numpy(), l.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "vmJPPLcWD3Y-"
      },
      "outputs": [],
      "source": [
        "# Функция для всей валидации на эпохе, будем использовать её также для получения предсказаний\n",
        "def validate(model, loss, device, val_dataloader):\n",
        "  model.eval()\n",
        "  val_loss = 0\n",
        "  preds = []\n",
        "  for batch in tqdm(val_dataloader):\n",
        "    preds_step, loss_step = valid_step(batch, model, loss, device)\n",
        "\n",
        "    val_loss += loss_step / len(val_dataloader)\n",
        "    preds.append(preds_step)\n",
        "\n",
        "  preds = np.concatenate(preds)\n",
        "\n",
        "  return preds, val_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UdNtY5MDMp3"
      },
      "source": [
        "Добавь в функцию `train_and_validate`:\n",
        "* вычисление `Accuracy` после валидации;\n",
        "* печать соответствующего лога.\n",
        "\n",
        "> **Добавь свой код в ячейки ниже.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "mhhe2WD4D5S4"
      },
      "outputs": [],
      "source": [
        "def train_and_validate(\n",
        "    epochs,\n",
        "    model,\n",
        "    loss,\n",
        "    optimizer,\n",
        "    device,\n",
        "    train_dataloader,\n",
        "    val_dataloader,\n",
        "    save_every=1,\n",
        "    naming=\"\",\n",
        "):\n",
        "\n",
        "    model.to(device)\n",
        "    best_acc = -1\n",
        "    for e in range(epochs):\n",
        "\n",
        "        train_loss = train(model, loss, optimizer, device, train_dataloader)\n",
        "        val_preds, val_loss = validate(model, loss, device, val_dataloader)\n",
        "\n",
        "        val_targets = torch.cat([y.to(device) for _, y in val_dataloader])\n",
        "        valid_acc = (val_preds == val_targets).numpy().mean()\n",
        "\n",
        "        print(\n",
        "            f\"Эпоха: {e} | Train Loss {train_loss} | Val Loss {val_loss} | Val_acc {valid_acc}\"\n",
        "        )  # Добавь в print полученное значение с соответствующей подписью\n",
        "\n",
        "        if e % save_every == 0 and valid_acc > best_acc:\n",
        "            torch.save(\n",
        "                model.state_dict(), f\"model_epoch_{e}{naming}_acc_{valid_acc:.4f}.pth\"\n",
        "            )\n",
        "            best_acc = valid_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "JBqM1uYKFvxb"
      },
      "outputs": [],
      "source": [
        "# Определяем модель с семинара, тут можешь ничего не трогать. Сеть с семинара подойдёт\n",
        "class FCMNIST(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__() # Не забываем super init сделать, без этого ничего работать не будет\n",
        "\n",
        "    # Линейный слой —> ReLU —> Линейный слой —> и так далее\n",
        "    self.net = nn.Sequential(\n",
        "        nn.Linear(784, 392),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(392, 191),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(191, 80),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(80, 40),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(40, 10)\n",
        "    )\n",
        "\n",
        "  def forward(self, X):\n",
        "    return self.net(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "mth8x0MVF34X"
      },
      "outputs": [],
      "source": [
        "model = FCMNIST()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-1)\n",
        "loss = (\n",
        "    nn.CrossEntropyLoss()\n",
        ")  # Кросс-энтропия, самая популярная функция потерь для решения задачи классификации. Разбиралась на лекциях\n",
        "epochs = 10\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "_hsXZDwsF7CB"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:07<00:00, 120.31it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 92.66it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 0 | Train Loss 0.9450430525436984 | Val Loss 0.22555837174877527 | Val_acc 0.9308\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:08<00:00, 116.33it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 126.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 1 | Train Loss 0.16474341814731247 | Val Loss 0.1269337734906003 | Val_acc 0.9612\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:07<00:00, 123.86it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 115.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 2 | Train Loss 0.10176988683338795 | Val Loss 0.09472787931445052 | Val_acc 0.9703\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:07<00:00, 123.82it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 114.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 3 | Train Loss 0.07262139084819495 | Val Loss 0.12415432278939986 | Val_acc 0.9605\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:07<00:00, 122.22it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 112.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 4 | Train Loss 0.056641450485206114 | Val Loss 0.10635024199436886 | Val_acc 0.9669\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:07<00:00, 121.25it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 113.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 5 | Train Loss 0.04357244413477257 | Val Loss 0.07794484012847533 | Val_acc 0.977\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:08<00:00, 107.55it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 110.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 6 | Train Loss 0.03487662771330815 | Val Loss 0.07897002380213965 | Val_acc 0.9774\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:09<00:00, 99.40it/s] \n",
            "100%|██████████| 40/40 [00:00<00:00, 104.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 7 | Train Loss 0.02697613312205072 | Val Loss 0.08071910812759597 | Val_acc 0.9785\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:08<00:00, 115.62it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 114.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 8 | Train Loss 0.020336058443156745 | Val Loss 0.08167582057876646 | Val_acc 0.9783\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:08<00:00, 116.87it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 110.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 9 | Train Loss 0.01629141951539698 | Val Loss 0.08388016428580157 | Val_acc 0.9792\n"
          ]
        }
      ],
      "source": [
        "# Запусти\n",
        "train_and_validate(epochs, model, loss, optimizer, device, train_dl, test_dl)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbwyPd_AH4qh"
      },
      "source": [
        "> **Важно.** Не забудь скачать веса лучшей модели!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKA6VD9IJhRl"
      },
      "source": [
        "Какие результаты у тебя получились? Является ли лучшая модель по loss также лучшей и по метрике?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsH3HM5CISMB"
      },
      "source": [
        "## Задача 2. Нормализация данных [4 балла]\n",
        "\n",
        "Мы уже нормализовали данные, чтобы улучшить качество решения линейных моделей. Для нейросетей это также хорошая практика.\n",
        "\n",
        "В этой задаче тебе предстоит сделать нормализацию выходных данных, а именно:\n",
        "1. Модифицировать класс датасета так, чтобы он нормализовал данные для обучения и выводил статистики train-подвыборки. **[2 балла]**\n",
        "2. Инициализировать класс с полученными статистиками для валидационной подвыборки. **[1 балл]**\n",
        "3. Обучить нейросеть и вывести все логи. **[0,5 балла]**\n",
        "4. Описать, что получилось. Стало ли лучше? **[0,5 балла]**\n",
        "\n",
        "Нормализация — это стандартизация наших данных. То есть мы вычитаем из нашей выборки среднее переменных по всей выборке и делим результат на стандартное отклонение выборки для каждой переменной:\n",
        "\n",
        "$$X_{norm} = \\frac{X - E(X)}{\\sqrt{V(X)}}.$$\n",
        "\n",
        "Также важно учесть, что, хоть у нас и векторы, мы работаем с картинками. Их нормализуют по каналам. Всего их обычно 3 (RGB — Red, Green, Blue). Но в нашем простом датасете канал всего один.\n",
        "\n",
        "То есть нужно получить всего одно число для среднего и стандартного отклонений, а не 784, если бы нормализовали данные как табличные."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pf5R-E1qTOvg"
      },
      "source": [
        "### Твоё решение задания 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "vwD_AezRaOM_"
      },
      "outputs": [],
      "source": [
        "class DatasetMNIST(Dataset):\n",
        "\n",
        "    def __init__(\n",
        "        self, X, y, mean=None, std=None\n",
        "    ):  # Теперь можно передавать статистики в датасет\n",
        "\n",
        "        # Тут всё как было\n",
        "        self.X = X.flatten(1) / 255\n",
        "        self.y = y\n",
        "\n",
        "        # Если у нас нет среднего или стандартного отклонения\n",
        "        if not mean or not std:\n",
        "            mean = self.X.mean()  # Посчитай среднее\n",
        "            std = self.X.std()  # Посчитай стандартное отклонение\n",
        "            print(\n",
        "                mean, std\n",
        "            )  # print, потому что init в Dataset не должен ничего возвращать по правилам PyTorch\n",
        "\n",
        "        self.X = (self.X - mean) / std\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cv8YoELEaOM_",
        "outputId": "c355dde1-dd91-4c47-d836-6ef56a77290c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.1307) tensor(0.3081)\n"
          ]
        }
      ],
      "source": [
        "# Надо пересоздать датасеты и даталоадеры\n",
        "# Определим train-датасет\n",
        "train_ds = DatasetMNIST(X_train, y_train)\n",
        "train_mean = train_ds.X.mean()\n",
        "train_std = train_ds.X.std()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "yscK7u_raOM_"
      },
      "outputs": [],
      "source": [
        "# Передай полученные статистики в наш валидационный датасет\n",
        "test_ds = DatasetMNIST(X_test, y_test, train_mean, train_std)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Zf_vGBK_aOM_"
      },
      "outputs": [],
      "source": [
        "# Определим даталоадеры\n",
        "train_dl = DataLoader(\n",
        "    train_ds, # Наш датасет\n",
        "    batch_size=64, # Размер батча. Меньше 32, согласно многим исследованиям, ставить не рекомендуется из-за потерь в качетсве\n",
        "    shuffle=True, # Указываем, перемешивать ли данные перед каждой эпохой (проходом по данным). Для train-подвыборки всегда ставим True, кроме единичных исключений\n",
        "    drop_last=True, # Если наш последний батч будет неполным, то не обучаемся на нём\n",
        "    num_workers=2, # Показывает, сколько процессов будет собирать данные в батч. Обычно выбирают по числу ядер\n",
        "    persistent_workers=True # Указываем, чтобы не создавать каждый раз новый процесс при обращении к DataLoader. Полезно для небольшого ускорения исполнения\n",
        ")\n",
        "\n",
        "test_dl = DataLoader(\n",
        "    test_ds, # Тестовый датасет\n",
        "    batch_size=64*4, # Для скорости можно побольше поставить, чем на train. Так как только получаем предсказания, а не обучаемся, нужно меньше ресурсов, а значит, в GPU поместится батч большего размера\n",
        "    shuffle=False, # Не будем перемешивать\n",
        "    drop_last=False, # И исключать неполный батч не будем, потому что нам нужны предсказания для него\n",
        "    num_workers=2,\n",
        "    persistent_workers=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "0XSzhT7CaONA"
      },
      "outputs": [],
      "source": [
        "# Инициализируем модель\n",
        "model = FCMNIST()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-1)\n",
        "loss = nn.CrossEntropyLoss() # Кросс-энтропия, самая популярная функция потерь для решения задачи классификации. Разбиралась на лекциях\n",
        "epochs = 10\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "kUyel7_VaONA"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:08<00:00, 115.36it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 95.18it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 0 | Train Loss 0.4588969342406587 | Val Loss 0.818739239871502 | Val_acc 0.9261\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:08<00:00, 114.87it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 110.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 1 | Train Loss 0.11104595965855912 | Val Loss 0.6017021045088765 | Val_acc 0.9361\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:08<00:00, 107.58it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 98.55it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 2 | Train Loss 0.07034198021100735 | Val Loss 0.5429601162672043 | Val_acc 0.9336\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:09<00:00, 101.60it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 103.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 3 | Train Loss 0.051465069312923405 | Val Loss 0.3629826106131078 | Val_acc 0.9624\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:08<00:00, 110.44it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 102.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 4 | Train Loss 0.03701780320910773 | Val Loss 0.3153669174760581 | Val_acc 0.947\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:08<00:00, 110.39it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 109.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 5 | Train Loss 0.02872456735998427 | Val Loss 0.3057440476492047 | Val_acc 0.9473\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:08<00:00, 109.40it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 102.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 6 | Train Loss 0.02069035928048529 | Val Loss 0.27281479574739936 | Val_acc 0.9449\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:08<00:00, 108.00it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 101.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 7 | Train Loss 0.016947414714312926 | Val Loss 0.2780557902529836 | Val_acc 0.9366\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:08<00:00, 109.39it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 101.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 8 | Train Loss 0.015380837148347213 | Val Loss 0.24832688309252268 | Val_acc 0.939\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:08<00:00, 109.23it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 72.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 9 | Train Loss 0.010167361669612745 | Val Loss 0.18675954630598426 | Val_acc 0.9594\n"
          ]
        }
      ],
      "source": [
        "# Запусти обучение\n",
        "train_and_validate(epochs, model, loss, optimizer, device, train_dl, test_dl, naming='_norm') # Здесь еще указали дополнительный нейминг модели, чтобы отличать веса"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfPNpNKgaONA"
      },
      "source": [
        "> **Важно.** Не забудь сохранить веса лучшей модели на валидации!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgQ5-RlBaONA"
      },
      "source": [
        "Удалось ли улучшить качество? Должно получиться где-то +0,1–0,3 п. п. к решению без нормализации. Если не вышло, не значит, что ты сделал что-то неправильно. Датасет настолько простой, что задача хорошо решается и без нормализации данных."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxBnNrsHcM_A"
      },
      "source": [
        "## Задача 3. BatchNorm [3 балла]\n",
        "\n",
        "Мы нормируем только входные данные. Но после каждого блока нейросети на выходе получаем новое представление наших данных. И нет никаких гарантий, что оно нормализовано, поэтому в нейросетях часто используют блок [BatchNorm](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html).\n",
        "\n",
        "Он нормализует наши данные, как мы это уже сделали вручную для входа. Зачем BatchNorm тогда нужен? Мы производим обучение по батчам. Удобно считать необходимые для нормализации среднее арифметическое и отклонение не по всей выборке, а у каждого батча, постепенно накапливая эти значения. Именно этим занимается BatchNorm!\n",
        "\n",
        "Также у этого слоя есть параметры: коэффициент умножения и сдвиг. Это нужно для того, чтобы слой мог при необходимости «отменить» или модифицировать эффект нормализации, унмножив или добавив определённое число.\n",
        "\n",
        "В этой задаче тебе предстоит поработать над архитектурой нейросети, добавив BatchNorm между слоями.\n",
        "\n",
        "BatchNorm может быть разным, для этой задачи используй [BatchNorm1d](https://www.google.com/url?q=https%3A%2F%2Fpytorch.org%2Fdocs%2Fstable%2Fgenerated%2Ftorch.nn.BatchNorm1d.html).\n",
        "\n",
        "Тебе нужно:\n",
        "1. Модифицировать нейросеть, добавив BatchNorm. **[1 балл]**\n",
        "\n",
        "Слой BatchNorm можно ставить как до, так и после функции активации. Можешь попробовать разные варианты и посмотреть, какой будет лучше!\n",
        "\n",
        "Этот слой принимает на вход один аргумент — размер входных данных. Поэтому, если на вход BatchNorm подаётся вектор длиной 100, надо инициализировать её через `nn.BatchNorm1d(100)`.\n",
        "2. Обучить все и сохранить лучшую модель. **[1 балла]**\n",
        "3. Описать, что получилось. **[1 балла]**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgkqfnZYfDZn"
      },
      "source": [
        "### Твоё решение задания 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "SHnGZ90jfwRF"
      },
      "outputs": [],
      "source": [
        "class NormFCMNIST(nn.Module): # Norm добавлено в название, чтобы различать классы\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__() # Не забываем super init сделать, без этого ничего работать не будет\n",
        "    # Не надо вставлять BatchNorm до и после активации. Выбери одно расположение\n",
        "    # Линейный слой —> (?Batchnorm) —> ReLU —> (?Batchnorm) —> Линейный слой —> и так далее\n",
        "    self.net = nn.Sequential(\n",
        "      \n",
        "        nn.Linear(784, 392),\n",
        "        nn.BatchNorm1d(392),\n",
        "        nn.ReLU(),\n",
        "        \n",
        "        nn.Linear(392, 191),\n",
        "        nn.BatchNorm1d(191),\n",
        "        nn.ReLU(),\n",
        "\n",
        "        nn.Linear(191, 80),\n",
        "        nn.BatchNorm1d(80),\n",
        "        nn.ReLU(),\n",
        "\n",
        "        nn.Linear(80, 40),\n",
        "        nn.BatchNorm1d(40),\n",
        "        nn.ReLU(),\n",
        "\n",
        "        nn.Linear(40, 10)\n",
        "    )\n",
        "\n",
        "  def forward(self, X):\n",
        "    return self.net(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZ6bVz3XAr3K"
      },
      "source": [
        "Объясни, куда ты добавил BatchNorm и почему?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "06LjvNERhPd_"
      },
      "outputs": [],
      "source": [
        "# Инициализируем модель\n",
        "model = NormFCMNIST()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-1)\n",
        "loss = nn.CrossEntropyLoss() # Кросс-энтропия, самая популярная функция потерь для решения задачи классификации. Разбиралась на лекциях\n",
        "epochs = 30\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "a3UIFcHChRmW"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:09<00:00, 97.26it/s] \n",
            "100%|██████████| 40/40 [00:00<00:00, 100.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 0 | Train Loss 0.21970959241813068 | Val Loss 1.7774486809968948 | Val_acc 0.4356\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:09<00:00, 99.14it/s] \n",
            "100%|██████████| 40/40 [00:00<00:00, 101.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 1 | Train Loss 0.0925591070470356 | Val Loss 2.9214424252510067 | Val_acc 0.2493\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:09<00:00, 100.45it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 107.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 2 | Train Loss 0.061923134707962096 | Val Loss 2.0896314442157746 | Val_acc 0.3925\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:10<00:00, 91.66it/s] \n",
            "100%|██████████| 40/40 [00:00<00:00, 97.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 3 | Train Loss 0.049014602904456486 | Val Loss 3.5556097507476805 | Val_acc 0.2036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:09<00:00, 97.55it/s] \n",
            "100%|██████████| 40/40 [00:00<00:00, 109.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 4 | Train Loss 0.03618387278333891 | Val Loss 4.282602989673614 | Val_acc 0.166\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:08<00:00, 104.13it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 105.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 5 | Train Loss 0.03043935468903442 | Val Loss 4.415924721956254 | Val_acc 0.1731\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:08<00:00, 104.69it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 110.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 6 | Train Loss 0.0256376460010957 | Val Loss 3.777851998805999 | Val_acc 0.1901\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:09<00:00, 96.99it/s] \n",
            "100%|██████████| 40/40 [00:00<00:00, 109.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 7 | Train Loss 0.021706792307528557 | Val Loss 4.3102478802204125 | Val_acc 0.1882\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:08<00:00, 106.66it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 111.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 8 | Train Loss 0.017304177288312156 | Val Loss 3.482607018947601 | Val_acc 0.1864\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:08<00:00, 106.51it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 107.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 9 | Train Loss 0.016021105631143683 | Val Loss 3.235571521520615 | Val_acc 0.2554\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:08<00:00, 106.92it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 108.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 10 | Train Loss 0.014342890350860485 | Val Loss 4.293786031007766 | Val_acc 0.1609\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:08<00:00, 108.08it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 115.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 11 | Train Loss 0.013819582801699036 | Val Loss 3.1878328859806055 | Val_acc 0.2683\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:08<00:00, 106.87it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 106.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 12 | Train Loss 0.009834384915429853 | Val Loss 3.537404662370682 | Val_acc 0.2276\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:08<00:00, 106.41it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 109.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 13 | Train Loss 0.010696607448228116 | Val Loss 3.736709636449813 | Val_acc 0.2349\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:08<00:00, 108.46it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 107.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 14 | Train Loss 0.008775771965842734 | Val Loss 3.358662009239197 | Val_acc 0.2537\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:08<00:00, 107.72it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 110.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 15 | Train Loss 0.007475643711390528 | Val Loss 3.140769910812378 | Val_acc 0.2867\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:08<00:00, 109.79it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 111.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 16 | Train Loss 0.005927849043889938 | Val Loss 3.5315753817558275 | Val_acc 0.2149\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:08<00:00, 109.05it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 110.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 17 | Train Loss 0.007110316769451406 | Val Loss 3.2899224042892454 | Val_acc 0.2494\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:08<00:00, 107.18it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 110.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 18 | Train Loss 0.005450359702279192 | Val Loss 3.600186723470688 | Val_acc 0.2041\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:08<00:00, 109.16it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 108.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 19 | Train Loss 0.005310221745311975 | Val Loss 3.1403802216053016 | Val_acc 0.2549\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:08<00:00, 107.90it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 100.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 20 | Train Loss 0.005786477201396482 | Val Loss 3.1070569038391107 | Val_acc 0.2668\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:10<00:00, 92.18it/s] \n",
            "100%|██████████| 40/40 [00:00<00:00, 84.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 21 | Train Loss 0.005172184450433634 | Val Loss 3.1796393692493434 | Val_acc 0.2477\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:11<00:00, 82.55it/s] \n",
            "100%|██████████| 40/40 [00:00<00:00, 81.08it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 22 | Train Loss 0.0036795119240613425 | Val Loss 3.0706350028514864 | Val_acc 0.271\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:08<00:00, 109.88it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 109.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 23 | Train Loss 0.004669316491403174 | Val Loss 3.3128356158733365 | Val_acc 0.2526\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:08<00:00, 109.04it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 108.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 24 | Train Loss 0.004102577359948733 | Val Loss 4.038648104667663 | Val_acc 0.2208\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:08<00:00, 106.21it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 109.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 25 | Train Loss 0.003993463438183427 | Val Loss 3.184399807453155 | Val_acc 0.274\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:08<00:00, 106.77it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 108.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 26 | Train Loss 0.004121461177563058 | Val Loss 3.7116491079330434 | Val_acc 0.2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:08<00:00, 108.46it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 111.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 27 | Train Loss 0.0049199856335610465 | Val Loss 3.425321418046951 | Val_acc 0.2304\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:08<00:00, 109.66it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 108.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 28 | Train Loss 0.003497308743448878 | Val Loss 3.898056185245514 | Val_acc 0.1796\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:08<00:00, 109.69it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 109.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 29 | Train Loss 0.0027629497014663835 | Val Loss 3.6882029712200173 | Val_acc 0.1982\n"
          ]
        }
      ],
      "source": [
        "# Запусти обучение\n",
        "train_and_validate(epochs, model, loss, optimizer, device, train_dl, test_dl, naming='_batchnorm') # Нейминг опять другой"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6krdxaFhTUU"
      },
      "source": [
        ">**Важно.** Не забудь сохранить веса лучшей модели на валидации!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LuVvdA8hW5R"
      },
      "source": [
        "Получилось ли у тебя улучшить результат? Что можно сказать про стабильность `loss` на валидации в сравнении с прошлыми моделями?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "нет, слишком сильно нормализует"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yADOA0TKhkFN"
      },
      "source": [
        "## Задание 4. Добавление шедулера [2 бонусных балла]\n",
        "\n",
        "Шедулеры разбирались на неделе, посвящённой оптимизации. Так как нейросети решают оптимизационные задачи, то для них также применяются шедулеры.\n",
        "\n",
        "В этом задании нужно:\n",
        "1. Добавить шедулер в код обучения. **[1 бонусный балл]**\n",
        "2. Выбрать шедулер и обучить с ним модель. **[0,5 бонусного балла]**\n",
        "3. Описать полученные результаты. **[0,5 бонусного балла]**\n",
        "\n",
        "Когда можно менять lr шедулером?\n",
        "* На каждом шаге оптимизатора (в этой задаче сделай так).\n",
        "* На каждой эпохе.\n",
        "\n",
        "> **Примечание.** При решении задачи в реальной жизни стоит попробовать оба варианта. Трудно заранее сказать, что лучше сработает для отдельно взятой задачи."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWFWeCNHnLer"
      },
      "source": [
        "### Твоё решение задания 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pd1mVdS-p57a"
      },
      "outputs": [],
      "source": [
        "# Функция для одного шага обучения. Подумай, куда добавить шедулер\n",
        "def train_step(batch, model, loss, optimizer, device, scheduler=None):\n",
        "\n",
        "    X, y = batch\n",
        "    X = X.to(device)\n",
        "    y = y.to(device)\n",
        "\n",
        "    logits = model(X)\n",
        "    l = loss(logits, y)\n",
        "\n",
        "    l.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "    if scheduler:\n",
        "        scheduler.step()\n",
        "    model.zero_grad()\n",
        "\n",
        "    return l.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "4hCZtCyRp-vj"
      },
      "outputs": [],
      "source": [
        "# Функция для обучения на эпохе. Тут уже аргумент scheduler прокидывается в train_step. То есть ничего тут писать не надо\n",
        "def train(model, loss, optimizer, device, train_dataloader, scheduler=None):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "\n",
        "    for batch in tqdm(train_dataloader):\n",
        "      loss_step = train_step(batch, model, loss, optimizer, device, scheduler)\n",
        "      train_loss += loss_step / len(train_dataloader)\n",
        "    return train_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLooGKAmnIxN"
      },
      "outputs": [],
      "source": [
        "def train_and_validate(\n",
        "    epochs,\n",
        "    model,\n",
        "    loss,\n",
        "    optimizer,\n",
        "    device,\n",
        "    train_dataloader,\n",
        "    val_dataloader,\n",
        "    save_every=1,\n",
        "    naming=\"\",\n",
        "    scheduler = None\n",
        "):\n",
        "\n",
        "    model.to(device)\n",
        "    best_acc = -1\n",
        "    for e in range(epochs):\n",
        "\n",
        "        train_loss = train(model, loss, optimizer, device, train_dataloader, scheduler=scheduler)\n",
        "        val_preds, val_loss = validate(model, loss, device, val_dataloader)\n",
        "\n",
        "        val_targets = torch.cat([y.to(device) for _, y in val_dataloader])\n",
        "        valid_acc = (val_preds == val_targets.cpu().numpy()).mean()\n",
        "\n",
        "        print(\n",
        "            f\"Эпоха: {e} | Train Loss {train_loss} | Val Loss {val_loss} | Val_acc {valid_acc}\"\n",
        "        )  # Добавь в print полученное значение с соответствующей подписью \n",
        "        if e % save_every == 0 and valid_acc > best_acc:\n",
        "            torch.save(\n",
        "                model.state_dict(), f\"../6/model_epoch_{e}{naming}{valid_acc}.pth\"\n",
        "            )\n",
        "            best_acc = valid_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mz48O-j-qTO7"
      },
      "source": [
        "Теперь тебе предстоит выбрать шедулер и его параметры. Как с ними быть?\n",
        "\n",
        "Обычно шедулер и его параметры выбирают такими, чтобы lr по мере обучения только снижался. Это помогает спуститься ещё глубже в минимум, что помогает качественно решить задачу.\n",
        "\n",
        "В PyTorch уже реализованы самые популярные шедулеры, например: [CosineAnnealingLR](https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.CosineAnnealingLR.html) (его идея объяснялась в ДЗ по оптимизации, но сейчас нужен только один цикл, чтобы lr снижался) или [LinearLR](https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.LinearLR.html).\n",
        "\n",
        "Можешь выбрать любой другой [шедулер](https://pytorch.org/docs/stable/optim.html#)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "T28AoE1ptS3M"
      },
      "outputs": [],
      "source": [
        "# Инициализируем модель\n",
        "model = NormFCMNIST()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-1)\n",
        "loss = nn.CrossEntropyLoss() # Кросс-энтропия, самая популярная функция потерь для решения задачи классификации. Разбиралась на лекциях\n",
        "epochs = 30\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.01)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "w6ur1vtBtS3N"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:08<00:00, 112.25it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 111.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 0 | Train Loss 0.22872927050795036 | Val Loss 2.1188090413808816 | Val_acc 0.2769\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:08<00:00, 112.85it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 89.87it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 1 | Train Loss 0.09316085541736158 | Val Loss 2.939431011676788 | Val_acc 0.243\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:08<00:00, 107.63it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 105.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 2 | Train Loss 0.06489902478593054 | Val Loss 3.2233971059322353 | Val_acc 0.224\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:08<00:00, 112.73it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 113.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 3 | Train Loss 0.0453000999097548 | Val Loss 3.9834652483463286 | Val_acc 0.2039\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:08<00:00, 113.69it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 112.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 4 | Train Loss 0.03713810226043617 | Val Loss 3.875023180246354 | Val_acc 0.208\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:08<00:00, 113.08it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 94.39it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 5 | Train Loss 0.02788281374097338 | Val Loss 3.492584997415542 | Val_acc 0.2293\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:08<00:00, 112.73it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 113.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 6 | Train Loss 0.024016501140030802 | Val Loss 4.714072263240815 | Val_acc 0.214\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:08<00:00, 114.41it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 110.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 7 | Train Loss 0.02061690652929719 | Val Loss 4.369006246328353 | Val_acc 0.2336\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:08<00:00, 111.96it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 111.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 8 | Train Loss 0.01847203701507862 | Val Loss 5.135568857192993 | Val_acc 0.1848\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:08<00:00, 110.93it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 112.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 9 | Train Loss 0.016400700954019288 | Val Loss 4.392016541957855 | Val_acc 0.2502\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:08<00:00, 112.89it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 114.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 10 | Train Loss 0.013088800176716153 | Val Loss 4.17951404452324 | Val_acc 0.2521\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:08<00:00, 112.93it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 112.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 11 | Train Loss 0.011170343736904988 | Val Loss 3.8969775617122657 | Val_acc 0.2399\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:08<00:00, 110.41it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 115.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 12 | Train Loss 0.009496074288820966 | Val Loss 5.099923479557038 | Val_acc 0.2193\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:08<00:00, 112.80it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 82.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 13 | Train Loss 0.008697402793641996 | Val Loss 4.098120343685151 | Val_acc 0.2415\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:08<00:00, 111.02it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 113.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 14 | Train Loss 0.007370519047232027 | Val Loss 4.463682854175568 | Val_acc 0.2453\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:08<00:00, 111.67it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 115.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 15 | Train Loss 0.005415080109359678 | Val Loss 4.250084167718887 | Val_acc 0.266\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:09<00:00, 102.56it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 100.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 16 | Train Loss 0.007876534448546956 | Val Loss 3.889149606227875 | Val_acc 0.2511\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:10<00:00, 92.06it/s] \n",
            "100%|██████████| 40/40 [00:00<00:00, 109.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 17 | Train Loss 0.006336867795559087 | Val Loss 4.791566348075866 | Val_acc 0.2273\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:08<00:00, 109.52it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 115.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 18 | Train Loss 0.0059771334155866215 | Val Loss 4.7540427565574666 | Val_acc 0.2106\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:08<00:00, 113.26it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 103.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 19 | Train Loss 0.0058559543513833955 | Val Loss 4.486263924837113 | Val_acc 0.2573\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:09<00:00, 102.07it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 112.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 20 | Train Loss 0.004972481132341345 | Val Loss 5.7245695114135735 | Val_acc 0.209\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:08<00:00, 110.10it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 110.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 21 | Train Loss 0.005782531489072046 | Val Loss 4.56264342069626 | Val_acc 0.2609\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:08<00:00, 112.07it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 110.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 22 | Train Loss 0.004613242438143785 | Val Loss 4.922450649738311 | Val_acc 0.2205\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:08<00:00, 109.32it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 117.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 23 | Train Loss 0.003286839438870896 | Val Loss 4.582103419303894 | Val_acc 0.2419\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:08<00:00, 112.26it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 114.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 24 | Train Loss 0.004397183227618721 | Val Loss 4.762594294548035 | Val_acc 0.2167\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:09<00:00, 103.70it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 118.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 25 | Train Loss 0.002843117536236838 | Val Loss 4.9075122594833385 | Val_acc 0.2367\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:08<00:00, 105.71it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 94.23it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 26 | Train Loss 0.003244522705896193 | Val Loss 4.875554621219635 | Val_acc 0.209\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:08<00:00, 106.64it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 111.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 27 | Train Loss 0.004055435189654578 | Val Loss 5.239970505237578 | Val_acc 0.178\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:08<00:00, 106.05it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 108.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 28 | Train Loss 0.003592657611456243 | Val Loss 5.129011368751525 | Val_acc 0.2083\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 937/937 [00:08<00:00, 106.98it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 108.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха: 29 | Train Loss 0.003505520208520793 | Val Loss 5.646620810031891 | Val_acc 0.1773\n"
          ]
        }
      ],
      "source": [
        "# Запусти обучение\n",
        "train_and_validate(epochs, model, loss, optimizer, device, train_dl, test_dl, naming='_sched', scheduler=scheduler) # Нейминг опять другой"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0vH1MTlf84t"
      },
      "source": [
        "> **Важно.** Не забудь сохранить веса лучшей модели!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8LS4bOXuKm3"
      },
      "source": [
        "Полчилось ли улучшить качество? Почему такой результат? Что можешь сказать про переобучение?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "В целом на мой взгляд получается, что мы слишком сильно регуляризируем из за чего нормально мы ничего не оптимизируем. Шедулер особо погоды не делает т.к мы не доходим до глобального минимума."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

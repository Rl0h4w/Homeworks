{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F # For convolution\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import multiprocessing\n",
    "from tqdm.notebook import tqdm # For progress bar (optional, replace with tqdm if not in notebook)\n",
    "import time\n",
    "import math\n",
    "\n",
    "# Optimization 1: Vectorized MRF Update using Convolution (Checkerboard)\n",
    "# Optimization 2: Batch Generation\n",
    "\n",
    "def generate_mrf_batched(\n",
    "    batch_size,\n",
    "    size=50,\n",
    "    interaction_strength=1.0,\n",
    "    external_field=0.0,\n",
    "    num_iterations=1000, # Note: Iterations here mean full grid updates (2 half-steps)\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "    \"\"\"\n",
    "    Генерирует батч бинарных матриц размера size x size с использованием модели Изинга (MRF)\n",
    "    с использованием векторизованного обновления (шахматная доска) на GPU.\n",
    "\n",
    "    Args:\n",
    "        batch_size (int): Количество карт для генерации в батче.\n",
    "        size (int): Размер матрицы (size x size).\n",
    "        interaction_strength (float): Сила взаимодействия (J).\n",
    "        external_field (float): Внешнее поле (h).\n",
    "        num_iterations (int): Количество полных итераций обновления сетки.\n",
    "        device (str): Устройство для вычислений ('cuda' или 'cpu').\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Батч бинарных матриц (0 и 1) размера (batch_size, size, size) на указанном устройстве.\n",
    "    \"\"\"\n",
    "    # Инициализация батча случайных бинарных матриц (-1 и 1)\n",
    "    state = torch.randint(0, 2, (batch_size, 1, size, size), dtype=torch.float32, device=device) * 2 - 1\n",
    "\n",
    "    # Ядро для суммирования соседей по фон Нейману\n",
    "    kernel = torch.tensor([[0, 1, 0],\n",
    "                           [1, 0, 1],\n",
    "                           [0, 1, 0]], dtype=torch.float32, device=device).reshape(1, 1, 3, 3)\n",
    "\n",
    "    # Маски для шахматного обновления\n",
    "    mask_white = torch.zeros((size, size), dtype=torch.bool, device=device)\n",
    "    mask_white[::2, ::2] = 1\n",
    "    mask_white[1::2, 1::2] = 1\n",
    "    mask_black = ~mask_white\n",
    "\n",
    "    # Расширяем маски до размера батча\n",
    "    mask_white = mask_white.unsqueeze(0).unsqueeze(0) # Shape (1, 1, size, size)\n",
    "    mask_black = mask_black.unsqueeze(0).unsqueeze(0) # Shape (1, 1, size, size)\n",
    "\n",
    "    for _ in range(num_iterations):\n",
    "        # --- Обновление \"белых\" клеток ---\n",
    "        # Вычисление суммы соседей для всех клеток одновременно\n",
    "        neighbor_sum = F.conv2d(state, kernel, padding=1) # padding=1 handles boundaries\n",
    "\n",
    "        # Локальное поле для всех клеток\n",
    "        local_field = external_field + interaction_strength * neighbor_sum\n",
    "\n",
    "        # Вероятность *не* переворота (остаться в текущем состоянии) P(s_i) ~ exp(-E_i)\n",
    "        # P(spin = s) = sigmoid(2 * s * local_field)\n",
    "        # Мы используем s = state[i, j]\n",
    "        prob_stay = torch.sigmoid(2 * state * local_field)\n",
    "\n",
    "        # Случайные числа для принятия решения\n",
    "        random_numbers = torch.rand_like(state)\n",
    "\n",
    "        # Обновляем только \"белые\" клетки: переворачиваем, если random_number > prob_stay\n",
    "        flip_condition_white = (random_numbers > prob_stay) & mask_white\n",
    "        state[flip_condition_white] *= -1\n",
    "\n",
    "        # --- Обновление \"черных\" клеток ---\n",
    "        # Повторное вычисление суммы соседей (т.к. белые могли измениться)\n",
    "        neighbor_sum = F.conv2d(state, kernel, padding=1)\n",
    "        local_field = external_field + interaction_strength * neighbor_sum\n",
    "        prob_stay = torch.sigmoid(2 * state * local_field)\n",
    "        random_numbers = torch.rand_like(state)\n",
    "\n",
    "        # Обновляем только \"черные\" клетки\n",
    "        flip_condition_black = (random_numbers > prob_stay) & mask_black\n",
    "        state[flip_condition_black] *= -1\n",
    "\n",
    "    # Преобразование к бинарным значениям (0 и 1) и удаление канала\n",
    "    binary_matrix_batch = ((state + 1) / 2).squeeze(1)\n",
    "    return binary_matrix_batch\n",
    "\n",
    "\n",
    "# Функция проверки перколяции остается без изменений, т.к. работает на CPU с numpy\n",
    "def check_percolation(binary_map):\n",
    "    \"\"\"\n",
    "    Проверяет наличие перколяции (связного пути из 1 от левой до правой границы)\n",
    "    в бинарной матрице.\n",
    "\n",
    "    Args:\n",
    "        binary_map (np.array): Бинарная матрица (0 и 1).\n",
    "\n",
    "    Returns:\n",
    "        int: 1, если перколяция есть, 0 в противном случае.\n",
    "    \"\"\"\n",
    "    rows, cols = binary_map.shape\n",
    "    if np.sum(binary_map[:, 0]) == 0: # Оптимизация: если нет 1 в первом столбце, перколяции нет\n",
    "        return 0\n",
    "\n",
    "    visited = np.zeros((rows, cols), dtype=bool)\n",
    "    queue = deque()\n",
    "\n",
    "    # Начало поиска из первого столбца\n",
    "    for r in range(rows):\n",
    "        if binary_map[r, 0] == 1: # and not visited[r, 0] (не нужно, т.к. visited[r,0] будет False)\n",
    "            queue.append((r, 0))\n",
    "            visited[r, 0] = True\n",
    "\n",
    "    while queue:\n",
    "        current_row, current_col = queue.popleft()\n",
    "\n",
    "        # Достигли правой границы\n",
    "        if current_col == cols - 1:\n",
    "            return 1\n",
    "\n",
    "        # Исследование соседей (оптимизировано)\n",
    "        for dr, dc in [(0, 1), (1, 0), (0, -1), (-1, 0)]: # Право, низ, лево, верх\n",
    "            neighbor_row, neighbor_col = current_row + dr, current_col + dc\n",
    "\n",
    "            # Проверка границ и условий (оптимизировано)\n",
    "            if (0 <= neighbor_row < rows and\n",
    "                0 <= neighbor_col < cols and\n",
    "                binary_map[neighbor_row, neighbor_col] == 1 and\n",
    "                not visited[neighbor_row, neighbor_col]):\n",
    "                visited[neighbor_row, neighbor_col] = True\n",
    "                queue.append((neighbor_row, neighbor_col))\n",
    "\n",
    "    return 0\n",
    "\n",
    "# Обертка для использования с multiprocessing.Pool\n",
    "def check_percolation_wrapper(args):\n",
    "    index, binary_map = args\n",
    "    return index, check_percolation(binary_map)\n",
    "\n",
    "# Optimization 3: Parallel Percolation Check using multiprocessing\n",
    "# Optimization 4: Batched GPU -> CPU Transfer\n",
    "# Optimization 5: Pre-allocation\n",
    "\n",
    "def create_percolation_dataset_optimized(\n",
    "    num_samples,\n",
    "    size=50,\n",
    "    interaction_strength=1.0,\n",
    "    external_field=0.0,\n",
    "    mrf_iterations=100, # Может потребоваться меньше итераций для сходимости с конволюцией\n",
    "    batch_size=64,      # Размер батча для GPU и параллельной обработки CPU\n",
    "    num_workers=None,   # Количество CPU процессов (None = cpu_count())\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "    \"\"\"\n",
    "    Создает датасет из бинарных карт (X) и их статуса перколяции (y),\n",
    "    используя оптимизированные методы генерации и проверки.\n",
    "\n",
    "    Args:\n",
    "        num_samples (int): Количество образцов для генерации.\n",
    "        size (int): Размер карт (size x size).\n",
    "        interaction_strength (float): Сила взаимодействия в MRF.\n",
    "        external_field (float): Внешнее поле в MRF.\n",
    "        mrf_iterations (int): Количество итераций для генерации MRF.\n",
    "        batch_size (int): Размер батча для обработки.\n",
    "        num_workers (int, optional): Количество процессов для проверки перколяции. Defaults to os.cpu_count().\n",
    "        device (str): Устройство для генерации MRF ('cuda' или 'cpu').\n",
    "\n",
    "    Returns:\n",
    "        tuple: Кортеж из двух numpy.ndarray:\n",
    "            - X: Массив бинарных карт размера (num_samples, size, size).\n",
    "            - y: Массив меток перколяции размера (num_samples,).\n",
    "    \"\"\"\n",
    "    if num_workers is None:\n",
    "        num_workers = multiprocessing.cpu_count()\n",
    "        print(f\"Using {num_workers} workers for percolation check.\")\n",
    "\n",
    "    # Пре-аллокация памяти\n",
    "    X_data = np.zeros((num_samples, size, size), dtype=np.float32) # Используем float32 для совместимости с PyTorch/np\n",
    "    y_labels = np.zeros(num_samples, dtype=np.int8) # int8 достаточно для 0/1\n",
    "\n",
    "    num_batches = math.ceil(num_samples / batch_size)\n",
    "    generated_count = 0\n",
    "\n",
    "    # Создаем пул процессов один раз\n",
    "    with multiprocessing.Pool(processes=num_workers) as pool:\n",
    "        with tqdm(total=num_samples, desc=\"Generating dataset\") as pbar:\n",
    "            for i in range(num_batches):\n",
    "                current_batch_size = min(batch_size, num_samples - generated_count)\n",
    "                if current_batch_size <= 0:\n",
    "                    break\n",
    "\n",
    "                # Шаг 1: Генерация батча карт на GPU\n",
    "                mrf_maps_batch_tensor = generate_mrf_batched(\n",
    "                    batch_size=current_batch_size,\n",
    "                    size=size,\n",
    "                    interaction_strength=interaction_strength,\n",
    "                    external_field=external_field,\n",
    "                    num_iterations=mrf_iterations,\n",
    "                    device=device\n",
    "                )\n",
    "\n",
    "                # Шаг 2: Перенос батча на CPU (один раз для всего батча)\n",
    "                # Используем .numpy(force=True) с PyTorch 1.12+ или .cpu().numpy()\n",
    "                try:\n",
    "                     mrf_maps_batch_cpu = mrf_maps_batch_tensor.cpu().numpy()\n",
    "                except AttributeError: # older Pytorch?\n",
    "                     mrf_maps_batch_cpu = mrf_maps_batch_tensor.numpy(force=True)\n",
    "\n",
    "\n",
    "                # Шаг 3: Параллельная проверка перколяции на CPU\n",
    "                # Подготовка аргументов для pool.imap_unordered\n",
    "                tasks = [(generated_count + j, mrf_maps_batch_cpu[j]) for j in range(current_batch_size)]\n",
    "\n",
    "                # Используем imap_unordered для получения результатов по мере готовности\n",
    "                for idx, percolates in pool.imap_unordered(check_percolation_wrapper, tasks):\n",
    "                    X_data[idx] = mrf_maps_batch_cpu[idx - generated_count] # Сохраняем карту\n",
    "                    y_labels[idx] = percolates                           # Сохраняем метку\n",
    "\n",
    "                generated_count += current_batch_size\n",
    "                pbar.update(current_batch_size)\n",
    "\n",
    "    return X_data, y_labels\n",
    "\n",
    "\n",
    "# --- Пример использования ---\n",
    "if __name__ == '__main__':\n",
    "    # Запускаем через if __name__ == '__main__': для совместимости с multiprocessing\n",
    "    multiprocessing.freeze_support() # Для Windows\n",
    "\n",
    "    num_data_points = 1000 # Увеличим для демонстрации скорости\n",
    "    map_size = 50\n",
    "    interaction = 0.8  # Пример значения (подберите для вашей задачи)\n",
    "    external_h = 0.0\n",
    "    # Для MCMC с конволюцией может потребоваться меньше итераций для \"смешивания\"\n",
    "    mrf_iters = 100\n",
    "    gpu_batch_size = 128 # Настройте в зависимости от VRAM\n",
    "    cpu_workers = 8    # Настройте в зависимости от количества ядер CPU\n",
    "\n",
    "    print(\"Starting Optimized Dataset Generation...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(f\"Using device: {device}\")\n",
    "    if device == 'cuda':\n",
    "         print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "\n",
    "    X_data_opt, y_labels_opt = create_percolation_dataset_optimized(\n",
    "        num_samples=num_data_points,\n",
    "        size=map_size,\n",
    "        interaction_strength=interaction,\n",
    "        external_field=external_h,\n",
    "        mrf_iterations=mrf_iters,\n",
    "        batch_size=gpu_batch_size,\n",
    "        num_workers=cpu_workers,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"\\nOptimized generation finished in {end_time - start_time:.2f} seconds.\")\n",
    "\n",
    "    print(f\"Размер набора карт (X): {X_data_opt.shape}\")\n",
    "    print(f\"Тип данных X: {X_data_opt.dtype}\")\n",
    "    print(f\"Размер меток перколяции (y): {y_labels_opt.shape}\")\n",
    "    print(f\"Тип данных y: {y_labels_opt.dtype}\")\n",
    "    # print(\"Пример меток:\", y_labels_opt[:20])\n",
    "    print(f\"Доля перколирующих карт: {np.mean(y_labels_opt):.3f}\")\n",
    "\n",
    "    # --- Сравнение с оригинальным (если нужно) ---\n",
    "    # print(\"\\nStarting Original Dataset Generation...\")\n",
    "    # start_time_orig = time.time()\n",
    "    # X_data_orig, y_labels_orig = create_percolation_dataset(\n",
    "    #     num_samples=num_data_points,\n",
    "    #     interaction_strength=interaction,\n",
    "    #     external_field=external_h,\n",
    "    #     mrf_iterations=2000, # Оригинальное количество итераций\n",
    "    #     device=device\n",
    "    # )\n",
    "    # end_time_orig = time.time()\n",
    "    # print(f\"Original generation finished in {end_time_orig - start_time_orig:.2f} seconds.\")\n",
    "    # print(f\"Размер набора карт (X_orig): {X_data_orig.shape}\")\n",
    "    # print(f\"Размер меток перколяции (y_orig): {y_labels_orig.shape}\")\n",
    "    # print(f\"Доля перколирующих карт (orig): {np.mean(y_labels_orig):.3f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
